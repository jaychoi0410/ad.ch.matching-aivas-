import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import io

# 1. ì‹œê°„ ì²˜ë¦¬ ë° ë³´ì • í•¨ìˆ˜
def handle_24h_time(date_str, time_str, offset_sec=0):
    try:
        if pd.isna(time_str) or str(time_str).strip() == "": return pd.NaT
        parts = str(time_str).strip().split(':')
        h, m = int(parts[0]), int(parts[1])
        s = int(parts[2]) if len(parts) > 2 else 0
        
        clean_date = str(date_str).replace('.', '-').split(' ')[0]
        date_dt = pd.to_datetime(clean_date)
            
        base_dt = None
        if h >= 24:
            days_to_add = h // 24
            actual_h = h % 24
            actual_date = date_dt + timedelta(days=days_to_add)
            base_dt = pd.to_datetime(f"{actual_date.strftime('%Y-%m-%d')} {actual_h:02d}:{m:02d}:{s:02d}")
        else:
            base_dt = pd.to_datetime(f"{date_dt.strftime('%Y-%m-%d')} {h:02d}:{m:02d}:{s:02d}")
            
        if offset_sec != 0:
            return base_dt + timedelta(seconds=offset_sec)
        return base_dt
    except:
        return pd.NaT

# 2. íŒŒì¼ ë¡œë”
def load_and_classify(uploaded_files):
    ad_df, incl_df, excl_df = None, None, None
    for file in uploaded_files:
        df_temp = None
        for skip in range(6):
            try:
                curr = pd.read_excel(file, skiprows=skip) if not file.name.endswith('.csv') else pd.read_csv(file)
                if not curr.empty and any(c in curr.columns for c in ['ê´‘ê³ ì†Œì¬ID', 'ê´‘ê³ ëª…', 'í”„ë¡œê·¸ë¨']):
                    df_temp = curr
                    break
            except: continue
        
        if df_temp is None: continue

        cols = df_temp.columns
        if 'ê´‘ê³ ì†Œì¬ID' in cols or 'ê´‘ê³ ëª…' in cols:
            ad_df = df_temp
            ad_df['ê¸°ì¤€ì¼ì'] = ad_df['ê¸°ì¤€ì¼ì'].ffill()
        elif 'í”„ë¡œê·¸ë¨' in cols:
            if 'ì œì™¸' in file.name or 'excl' in file.name.lower():
                excl_df = df_temp
            else:
                incl_df = df_temp
            
    return ad_df, incl_df, excl_df

# UI ì„¤ì •
st.set_page_config(page_title="AIVAS ì§€ëŠ¥í˜• ë§¤ì¹­ ì—ì´ì „íŠ¸", layout="wide")
st.title("ğŸ•’ (AIVAS) ì§€ëŠ¥í˜• ê´‘ê³  í¬ì§€ì…˜ íŒì • ì‹œìŠ¤í…œ")
st.markdown("í¸ì„± ê³µë°± ë° ì‹œê°„ ë³´ì • ë¡œì§ì„ ì ìš©í•˜ì—¬ ë§¤ì¹­ ì‚¬ìœ ë¥¼ ìƒì„¸í™”í•©ë‹ˆë‹¤.")

with st.sidebar:
    st.header("âš™ï¸ ë¡œì§ ì„¤ì •")
    time_offset = st.number_input("ì‹œê°„ ë³´ì •ê°’ (ì´ˆ)", value=-3)
    gap_threshold = st.number_input("ê³µë°± í—ˆìš© ë²”ìœ„ (ë¶„)", value=30, help="í”„ë¡œê·¸ë¨ ì‚¬ì´ ê³µë°±ì´ ì´ ì‹œê°„ ì´ë‚´ë©´ ë§¤ì¹­í•©ë‹ˆë‹¤.")

uploaded_files = st.file_uploader("ğŸ“‚ íŒŒì¼ 3ê°œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['xlsx', 'csv'], accept_multiple_files=True)

if uploaded_files:
    df_ad, df_incl, df_excl = load_and_classify(uploaded_files)
    
    if df_ad is not None and df_incl is not None and df_excl is not None:
        if st.button("ğŸš€ ì§€ëŠ¥í˜• ë§¤ì¹­ ì‹¤í–‰"):
            ref_date = str(df_ad['ê¸°ì¤€ì¼ì'].iloc[0])
            channel_name = str(df_ad['ì±„ë„'].iloc[0]) if 'ì±„ë„' in df_ad.columns else "ì±„ë„ëª…ë¯¸í™•ì¸"
            
            # í¸ì„±í‘œ ì „ì²˜ë¦¬
            for target in [df_incl, df_excl]:
                target['dt_start'] = target.apply(lambda r: handle_24h_time(ref_date, r['ì‹œì‘ì‹œê°„']), axis=1)
                target['dt_end'] = target.apply(lambda r: handle_24h_time(ref_date, r['ì¢…ë£Œì‹œê°„']), axis=1)

            results = []
            for _, row in df_ad.iterrows():
                if "ê´‘ê³ ì—†ìŒ" in str(row['ê´‘ê³ ëª…']) or str(row['ê´‘ê³ ì†Œì¬ID']) == "ê´‘ê³ ì•„ë‹˜": continue
                
                # AIVAS ì‹œê°„ ë³´ì • ì ìš©
                ad_time_corr = handle_24h_time(row['ê¸°ì¤€ì¼ì'], row['ì‹œì‘ì¼ì‹œ'], offset_sec=time_offset)
                if pd.isna(ad_time_corr): continue
                
                # [ë¡œì§] ë§¤ì¹­ ì‹œë„
                match_reason = "ê²€í†  í•„ìš”"
                target_match = df_incl[(df_incl['dt_start'] <= ad_time_corr) & (df_incl['dt_end'] > ad_time_corr)]
                
                # Case 1: ì •ìƒ ìŠ¬ë¡¯ ë§¤ì¹­
                if not target_match.empty:
                    match_reason = "ì •ìƒ ë§¤ì¹­"
                    final_match = target_match.iloc[0]
                # Case 2: í¸ì„± ê³µë°±(Gap) ì²˜ë¦¬ (Case A)
                else:
                    # ë³´ì • ì‹œê°ë³´ë‹¤ ëŠ¦ê²Œ ì‹œì‘í•˜ëŠ” ê°€ì¥ ê°€ê¹Œìš´ í”„ë¡œê·¸ë¨ ì°¾ê¸°
                    future_progs = df_incl[df_incl['dt_start'] > ad_time_corr].sort_values('dt_start')
                    if not future_progs.empty:
                        next_prog = future_progs.iloc[0]
                        # ê³µë°±ì´ ì„¤ì •í•œ í—ˆìš© ë²”ìœ„ ì´ë‚´ì¸ì§€ í™•ì¸
                        gap_duration = (next_prog['dt_start'] - ad_time_corr).total_seconds() / 60
                        if gap_duration <= gap_threshold:
                            final_match = next_prog
                            match_reason = "ì •ìƒ ë§¤ì¹­(í¸ì„± ê³µë°± - ì°¨ê¸° í”„ë¡œê·¸ë¨ ì „ê´‘ê³  ê°„ì£¼)"
                        else:
                            final_match = None
                    else:
                        final_match = None

                # ê²°ê³¼ ë°ì´í„° ìƒì„±
                if final_match is not None:
                    prog_name = final_match['í”„ë¡œê·¸ë¨']
                    excl_info = df_excl[df_excl['í”„ë¡œê·¸ë¨'] == prog_name]
                    prog_section, pos = "", "íŒì •ë¶ˆê°€"
                    
                    if not excl_info.empty:
                        ex_s_dt, ex_e_dt = excl_info.iloc[0]['dt_start'], excl_info.iloc[0]['dt_end']
                        ex_s_str, ex_e_str = excl_info.iloc[0]['ì‹œì‘ì‹œê°„'], excl_info.iloc[0]['ì¢…ë£Œì‹œê°„']
                        
                        if ad_time_corr >= ex_s_dt and ad_time_corr < ex_e_dt:
                            pos, prog_section = "ì¤‘ê´‘ê³ ", f"â— í”„ë¡œê·¸ë¨ ì§„í–‰ ì¤‘({ex_s_str}~{ex_e_str}) â—"
                        elif ad_time_corr < ex_s_dt:
                            pos = "ì „ê´‘ê³ "
                        else:
                            pos = "í›„ê´‘ê³ "

                    results.append({
                        'ì¼ì': pd.to_datetime(ref_date).strftime('%Y-%m-%d'),
                        'ì‹œì‘ì‹œê°„': row['ì‹œì‘ì¼ì‹œ'],
                        'ì¢…ë£Œì‹œê°„': row['ì¢…ë£Œì¼ì‹œ'],
                        'ê´‘ê³ ì£¼': str(row['ê´‘ê³ ëª…']).split('_')[0] if '_' in str(row['ê´‘ê³ ëª…']) else "-",
                        'ìƒí’ˆëª…': row['ê´‘ê³ ëª…'],
                        'ê´‘ê³ ìœ í˜•': "",
                        '[í”„ë¡œê·¸ë¨ êµ¬ê°„]': prog_section,
                        'ë§¤ì¹­ í”„ë¡œê·¸ë¨ëª…': prog_name,
                        'ìµœì¢… íŒì • ìœ„ì¹˜': pos,
                        'ì‚¬ìœ ': match_reason
                    })
                else:
                    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ
                    results.append({
                        'ì¼ì': pd.to_datetime(ref_date).strftime('%Y-%m-%d'),
                        'ì‹œì‘ì‹œê°„': row['ì‹œì‘ì¼ì‹œ'],
                        'ì¢…ë£Œì‹œê°„': row['ì¢…ë£Œì¼ì‹œ'],
                        'ê´‘ê³ ì£¼': str(row['ê´‘ê³ ëª…']).split('_')[0] if '_' in str(row['ê´‘ê³ ëª…']) else "-",
                        'ìƒí’ˆëª…': row['ê´‘ê³ ëª…'],
                        'ê´‘ê³ ìœ í˜•': "",
                        '[í”„ë¡œê·¸ë¨ êµ¬ê°„]': "",
                        'ë§¤ì¹­ í”„ë¡œê·¸ë¨ëª…': "ë¯¸ë§¤ì¹­",
                        'ìµœì¢… íŒì • ìœ„ì¹˜': "íŒì •ë¶ˆê°€",
                        'ì‚¬ìœ ': "ê²€í†  í•„ìš”(ë§¤ì¹­ í”„ë¡œê·¸ë¨ ì—†ìŒ)"
                    })

            if results:
                res_df = pd.DataFrame(results)
                st.dataframe(res_df, use_container_width=True)
                
                mmdd = pd.to_datetime(ref_date).strftime('%m%d')
                filename = f"(AIVAS)ê´‘ê³ -í”„ë¡œê·¸ë¨_ë§¤ì¹­_ê²°ê³¼_{mmdd}({channel_name}).xlsx"
                
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    res_df.to_excel(writer, index=False, sheet_name='Result')
                st.download_button(f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ", output.getvalue(), filename)
